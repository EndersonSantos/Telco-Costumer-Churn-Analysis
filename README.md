# Telco Costumer Churn Predictions

## Asking 
Telco Systems is a global leader in telecommunications, with over 40 years of experience in the design and development of high-performance network communications solutions. With its advanced software and hardware solutions, Telco Systems provides a revolutionary approach to the network edge for service providers, allowing them to offer the highest levels of service innovation to customers. Thus has a lot of available data from your costumers that can be used to answers interesting questions that cand lead to data driving decisions.
Some of the question that we would like to answers is:

**Based on historical data can we predict churn?** 
**Which kind of retentions programns can we develop focused on diminished the churn rate?**

## Prepare 
The problem that we want to attach is clear so now lets move on for what data do we need in order to solve this problem. And, it's obvious that we need data related to the customers. Luckly we can find this on Kaggle data sets.
The data was collected from [IBM Samples Data Sets](https://community.ibm.com/community/user/businessanalytics/blogs/steven-macko/2019/07/11/telco-customer-churn-1113) and the last updated was made on 23-02-2018. And, is under the licence guaranteed by kaggle comunity Data files © Original Authors.
We going to proceed our analysis and training modeling on this data set of course would be better to have on hands a more recent dataset.
This data contains information about:
- Customers that left within the last month - *churn*
- Services that each customer has signed up for – *phone, multiple lines, internet, online security, online backup, device protection, tech support, and streaming TV and movies*
- Customer account information – *how long they’ve been a customer, contract, payment method, paperless billing, monthly charges, and total charges*
- Demographic info about customers – *gender, age range, and if they have partners and dependents.*
This data will allow us to answer our first question since the last would be a matter of interpretation of the results.

## Process
The data is already cleaned so we not going to do nothing in this matters although is probaly one of the most important step. So we going to focus on our exploratory data analysis, vizualizations and training modeling to propel data driven decisions.
The tools that we going to use is Python and its main libraries like:
**Pandas: For Exploratory Data Analysis.
**Dash: For creating a dashboard to show the means findings from the previous step.
**Jupiter Note Book: For data Handling. 
**Skit-Learn - For training different models and avaluate its performances. 

## Analyse 

